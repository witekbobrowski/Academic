{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (Summer 2017)\n",
    "\n",
    "## Homework 2:\n",
    "\n",
    "\n",
    "- Implement Naive Bayes model (remember about smoothing). \n",
    "- Find a reasonably interesting but not to complicated dataset for which you will be able to use this model to perform binary classification. Do the latter.\n",
    "- Produce the confussion matrix, calculate accuracy, precission, recall\n",
    "- Check how your model does against its version from sklearn and logistic regression from sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    \n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.features = [np.unique(X[:,column]) for column in range(X.shape[1])]\n",
    "        grouped = [[x for x, t in zip(X, y) if t == c] for c in self.classes]\n",
    "        self.class_log_prior = [np.log(len(group)/X.shape[0]) for group in grouped]\n",
    "        self.log_probs = self.feature_log_probs(grouped)\n",
    "        return self\n",
    "    \n",
    "    def log_prob(self, amount, total, unique):\n",
    "        return np.log((amount + self.alpha)/np.sum(total + (unique * self.alpha)))\n",
    "    \n",
    "    def feature_log_probs(self, grouped):\n",
    "        group_counts = [[np.unique(column, return_counts=True) for column in np.array(group).T] for group in grouped]\n",
    "        counts_dicts = [[{k:v for k, v in zip(count[0],count[1])} for count in group] for group in group_counts]\n",
    "        return [[[self.log_prob(d.get(key, 0), sum(d.values()),feature.shape[0]) for key in feature] for feature, d in zip(self.features, c)] for c in counts_dicts]\n",
    "    \n",
    "    def get_log_probs(self, row):\n",
    "        inidices = [np.where(keys == key)[0][0] for keys, key in zip(self.features, row)]\n",
    "        return [[f_probs[index] for f_probs, index in zip(c_probs, inidices)] for c_probs in self.log_probs]\n",
    "    \n",
    "    def predict_log_prob(self, X):\n",
    "        return [np.array(self.get_log_probs(x)).sum(axis=1) + self.class_log_prior for x in X]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_prob(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data set\n",
    "\n",
    "Source: [Car Evaluation Data Set ](https://archive.ics.uci.edu/ml/datasets/car+evaluation)\n",
    "\n",
    "**Class values:**   \n",
    "unacc, acc, good, vgood\n",
    "\n",
    "**Attributes:**\n",
    "- buying:   vhigh, high, med, low.\n",
    "- maint:    vhigh, high, med, low.\n",
    "- doors:    2, 3, 4, 5more.\n",
    "- persons:  2, 4, more.\n",
    "- lug_boot: small, med, big.\n",
    "- safety:   low, med, high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '~/Downloads/'\n",
    "\n",
    "attributes = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "cars_dataset = pd.read_csv(DATASET_DIR+'car.data.txt')\n",
    "cars_dataset.columns = attributes + ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    med  unacc\n",
       "1  vhigh  vhigh     2       2    small   high  unacc\n",
       "2  vhigh  vhigh     2       2      med    low  unacc\n",
       "3  vhigh  vhigh     2       2      med    med  unacc\n",
       "4  vhigh  vhigh     2       2      med   high  unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glossary(dataset):\n",
    "    unique_values_per_column = [np.unique(column) for column in dataset.T]\n",
    "    glossary = [{key:index for index, key in enumerate(column)} for column in unique_values_per_column]\n",
    "    return glossary\n",
    "\n",
    "def convert_entry(entry, glossary):\n",
    "    converted = [keys[feature] for feature, keys in zip(entry, glossary)]\n",
    "    return np.array(converted)\n",
    "\n",
    "def convert_dataset(dataset):\n",
    "    glossary = extract_glossary(dataset)\n",
    "    converted = [convert_entry(entry, glossary) for entry in dataset]\n",
    "    return glossary, np.array(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using methods above we can convert the whole dataset with `int` values insted of `string`. This will make the whole thing easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glossary, dataset = convert_dataset(np.array(cars_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can compare the head of converted data set using printed glossary to the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "maint {'high': 0, 'low': 1, 'med': 2, 'vhigh': 3}\n",
      "doors {'2': 0, '3': 1, '4': 2, '5more': 3}\n",
      "persons {'2': 0, '4': 1, 'more': 2}\n",
      "lug_boot {'big': 0, 'med': 1, 'small': 2}\n",
      "safety {'high': 0, 'low': 1, 'med': 2}\n",
      "class {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3}\n"
     ]
    }
   ],
   "source": [
    "_ = [print(attribute, keys) for attribute, keys in zip(attributes + ['class'], glossary)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X, y, train_ratio=0.8, alpha=1.0):\n",
    "    nb = MultinomialNaiveBayes(alpha)\n",
    "    train_X, train_y = X[:int(X.shape[0] * train_ratio)], y[:int(y.shape[0] * train_ratio)]\n",
    "    nb.fit(train_X, train_y)\n",
    "    predict_X, predict_y = X[int(X.shape[0] * train_ratio):], y[int(y.shape[0] * train_ratio):]\n",
    "    return nb.predict(predict_X), predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:-1]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "result, target = naive_bayes(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets evaluate the results taking `acc` class into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glossary[-1]\n",
    "t_class_name = \"acc\"\n",
    "t_class = classes[t_class_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Confusion matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(results, target, classes):\n",
    "    if len(results) != len(target):\n",
    "        return None\n",
    "    matrix = np.zeros(shape=(len(classes),len(classes)))\n",
    "    for r, t in zip(results, target):\n",
    "        matrix[r][t] += 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3} \n",
      " [[  38.   46.    2.   39.]\n",
      " [   0.    0.    0.    0.]\n",
      " [  25.    0.  196.    0.]\n",
      " [   0.    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "cm = get_confusion_matrix(result, target, classes)\n",
    "print(\"Confusion matrix:\\n\", classes, \"\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Table of confusion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_of_confusion(confusion_matrix, t_class):\n",
    "    table = np.zeros(shape=(2,2))\n",
    "    for i_r, result in enumerate(confusion_matrix):\n",
    "        for i_t, target in enumerate(confusion_matrix[i_r]):\n",
    "            if i_r == t_class:\n",
    "                if i_t == t_class:\n",
    "                    table[0][0] += confusion_matrix[i_r][i_t]\n",
    "                else:\n",
    "                    table[0][1] += confusion_matrix[i_r][i_t]\n",
    "            else:\n",
    "                if i_t == t_class:\n",
    "                    table[1][0] += confusion_matrix[i_r][i_t]\n",
    "                else:\n",
    "                    table[1][1] += confusion_matrix[i_r][i_t]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table of confusion:\n",
      " ['acc', 'non-acc'] \n",
      " [[  38.   87.]\n",
      " [  25.  196.]]\n"
     ]
    }
   ],
   "source": [
    "toc = get_table_of_confusion(cm, t_class)\n",
    "print(\"table of confusion:\\n\", [t_class_name, \"non-\" + t_class_name], \"\\n\", toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(table_of_confusion):\n",
    "    return (table_of_confusion[0][0]+table_of_confusion[1][1])/sum(sum(table_of_confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class \"acc\" : 0.676300578035\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(toc)\n",
    "print(\"Accuracy for class\", '\"' + t_class_name + '\"' ,\":\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Precision__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(table_of_confusion):\n",
    "    return (table_of_confusion[0][0])/(table_of_confusion[0][0]+toc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class \"acc\" : 0.304\n"
     ]
    }
   ],
   "source": [
    "precision = get_precision(toc)\n",
    "print(\"Precision for class\", '\"' + t_class_name + '\"' ,\":\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recall__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(table_of_confusion):\n",
    "    return (table_of_confusion[0][0])/(table_of_confusion[0][0]+table_of_confusion[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for class \"acc\" : 0.603174603175\n"
     ]
    }
   ],
   "source": [
    "recall = get_recall(toc)\n",
    "print(\"Recall for class\", '\"' + t_class_name + '\"' ,\":\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparsion with sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_nb(X, y, train_ratio=0.8, alpha=1.0):\n",
    "    nb = MultinomialNB()\n",
    "    train_X, train_y = X[:int(X.shape[0] * train_ratio)], y[:int(y.shape[0] * train_ratio)]\n",
    "    nb.fit(train_X, train_y)\n",
    "    predict_X, predict_y = X[int(X.shape[0] * train_ratio):], y[int(y.shape[0] * train_ratio):]\n",
    "    return nb.predict(predict_X), predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_result, sk_target = sklearn_nb(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3} \n",
      " [[   0.    0.    0.    6.]\n",
      " [   0.    0.    0.    0.]\n",
      " [  63.   46.  198.   33.]\n",
      " [   0.    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "sk_cm = get_confusion_matrix(sk_result, sk_target, classes)\n",
    "print(\"Confusion matrix:\\n\", classes, \"\\n\", sk_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table of confusion:\n",
      " ['acc', 'non-acc'] \n",
      " [[   0.    6.]\n",
      " [  63.  277.]]\n"
     ]
    }
   ],
   "source": [
    "sk_toc = get_table_of_confusion(sk_cm, t_class)\n",
    "print(\"table of confusion:\\n\", [t_class_name, \"non-\" + t_class_name], \"\\n\", sk_toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class \"acc\" : 0.800578034682\n"
     ]
    }
   ],
   "source": [
    "sk_accuracy = get_accuracy(sk_toc)\n",
    "print(\"Accuracy for class\", '\"' + t_class_name + '\"' ,\":\", sk_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for class \"acc\" : 0.0\n"
     ]
    }
   ],
   "source": [
    "sk_precision = get_precision(sk_toc)\n",
    "print(\"Precision for class\", '\"' + t_class_name + '\"' ,\":\", sk_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for class \"acc\" : 0.0\n"
     ]
    }
   ],
   "source": [
    "sk_recall = get_recall(sk_toc)\n",
    "print(\"Recall for class\", '\"' + t_class_name + '\"' ,\":\", sk_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
